{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit (conda)",
   "display_name": "Python 3.7.6 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "cf5781ee9688be887a830af3862a813ef5b0a355a8789de10c6994358407057c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        word  count\n0    abandon   -2.0\n1  abandoned   -2.0\n2   abandons   -2.0\n3   abducted   -2.0\n4  abduction   -2.0\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "data_path = \"../data/\"\n",
    "sa_df = pd.read_csv(data_path + \"sentiment_analysis.csv\", names=[\"ID\", \"text\", \"label\"], low_memory=False)\n",
    "us_df = pd.read_csv(data_path + \"US_Elections_2020.csv\", names=[\"text\", \"sentiment\", \"negative_reason\"], low_memory=False)\n",
    "# 665 lines in stop_words.txt\n",
    "stop_words_file_len = 665\n",
    "stop_words_file = open(data_path + \"stop_words.txt\")\n",
    "stop_words = np.array([\" \" for _ in range(stop_words_file_len)], dtype=object)\n",
    "\n",
    "index = 0\n",
    "for line in stop_words_file:\n",
    "    stop_words[index] = line.replace(\"\\n\", \"\")\n",
    "    index += 1\n",
    "\n",
    "# 2477 lines in corpus.txt\n",
    "corpus_file_len = 2477\n",
    "corpus_file = open(data_path + \"corpus.txt\")\n",
    "corpus_words = np.array([\" \" for _ in range(corpus_file_len)], dtype=object)\n",
    "corpus_counts = np.zeros((corpus_file_len,))\n",
    "\n",
    "index = 0\n",
    "\n",
    "def sum_line_array(line_array_splice):\n",
    "    string = \"\"\n",
    "    for word in line_array_splice:\n",
    "        string += word + \" \"\n",
    "    return string[:-1]\n",
    "\n",
    "for line in corpus_file:\n",
    "    line_array = line.split()\n",
    "    corpus_words[index], corpus_counts[index] = sum_line_array(line_array[:-1]), line_array[-1]\n",
    "    index += 1\n",
    "\n",
    "corpus_df_dict = {\"word\": pd.Series(corpus_words), \"count\": pd.Series(corpus_counts)}\n",
    "corpus_df = pd.DataFrame(corpus_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of sentiment analysis DataFrame: (550392, 3)\nShape of US elections DataFrame: (2553, 3)\nShape of corpus DataFrame: (2477, 2)\nShape of stop words np.array: (665,)\ndf.head of sentiment analysis DataFrame:\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of sentiment analysis DataFrame:\", sa_df.shape)\n",
    "print(\"Shape of US elections DataFrame:\", us_df.shape)\n",
    "print(\"Shape of corpus DataFrame:\", corpus_df.shape)\n",
    "print(\"Shape of stop words np.array:\", stop_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "df.head of sentiment analysis DataFrame:             ID                                               text  label\n0           ID                                               text  label\n1  7.68098E+17  Josh Jenkins is looking forward to TAB Breeder...      1\n2  7.68098E+17  RT @MianUsmanJaved: Congratulations Pakistan o...      1\n3  7.68098E+17  RT @PEPalerts: This September, @YESmag is taki...      1\n4  7.68098E+17  RT @david_gaibis: Newly painted walls, thanks ...      1\n\ndf.head of US elections DataFrame:                                                 text  sentiment  \\\n0                                               text  sentiment   \n1  b'@robreiner so afraid of Nov, Dec, and Jan! E...          0   \n2  b\"RT @SueC00K: Lord Sumption launches Recovery...          0   \n3  b'RT @WalidPhares: Uber Timing: after #Biden a...          0   \n4  b'Every 107 seconds an American is dying from ...          1   \n\n   negative_reason  \n0  negative_reason  \n1          covid19  \n2           others  \n3          covid19  \n4              NaN  \n\ndf.head of corpus DataFrame:         word  count\n0    abandon   -2.0\n1  abandoned   -2.0\n2   abandons   -2.0\n3   abducted   -2.0\n4  abduction   -2.0\nIndex(['text', 'sentiment', 'negative_reason'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"df.head of sentiment analysis DataFrame:\", sa_df.head())\n",
    "print(\"\\ndf.head of US elections DataFrame:\", us_df.head())\n",
    "print(\"\\ndf.head of corpus DataFrame:\", corpus_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning tweet data\n",
    "# - replacing html tags and attributes (/<[^>]+>\\)\n",
    "def replace_html(element):\n",
    "    unwanted_html_elements = \"/<[^>]+>\"    \n",
    "    for unwanted_element in unwanted_html_elements:\n",
    "        element = element.replace(unwanted_element, \"\")\n",
    "    return element\n",
    "\n",
    "sa_df[\"text\"] = sa_df[\"text\"].map(replace_html)\n",
    "us_df[\"text\"] = us_df[\"text\"].map(replace_html)\n",
    "\n",
    "# - replacing html character codes (&...)\n",
    "\n",
    "# removing URLs\n",
    "\n",
    "# changing text to lowercase\n",
    "\n",
    "# removing stop words\n",
    "\n",
    "# preserving empty tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}